{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Aktg8TXfA6K",
        "outputId": "5584c274-eb5c-4ae3-d500-e0636c0fa6a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (0.58.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba) (0.41.1)\n",
            "Requirement already satisfied: numpy<1.27,>=1.22 in /usr/local/lib/python3.10/dist-packages (from numba) (1.23.5)\n",
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "! pip install numba\n",
        "import numba\n",
        "from numba import cuda\n",
        "from numba.cuda.cudadrv import enums\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import time\n",
        "from numba import vectorize\n",
        "import math\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")\n",
        "\n",
        "params = {\n",
        "    'figure.figsize': [15, 10],  # instead of 4.5, 4.5\n",
        "    'axes.titlesize': 15,\n",
        "    'axes.labelsize': 10,\n",
        "    'axes.linewidth': 0.5,\n",
        "    'font.size': 20,\n",
        "    'font.family': 'monospace',\n",
        "    #    'font.monospace': 'Alma Mono',\n",
        "    'legend.fontsize': 15,\n",
        "    'legend.loc': 'upper right',\n",
        "    'legend.labelspacing': 0.25,\n",
        "    # 'xtick.labelsize': 20,\n",
        "    # 'ytick.labelsize': 20,\n",
        "    'lines.linewidth': 3,\n",
        "    'text.usetex': False,\n",
        "    # 'figure.autolayout': True,\n",
        "    'ytick.right': False,\n",
        "    'xtick.top': False,\n",
        "\n",
        "    'xtick.major.size': 5,\n",
        "    'ytick.major.size': 5,\n",
        "    'xtick.minor.size': 5,\n",
        "    'ytick.minor.size': 5,\n",
        "    'xtick.labelsize': 15,\n",
        "    'ytick.labelsize': 15,\n",
        "\n",
        "    'xtick.major.width': 2,\n",
        "    'ytick.major.width': 2,\n",
        "    'xtick.minor.width': 1,\n",
        "    'ytick.minor.width': 1,\n",
        "\n",
        "    'xtick.major.pad': 2,\n",
        "    'ytick.major.pad': 2,\n",
        "    # 'xtick.minor.pad': 14,\n",
        "    # 'ytick.minor.pad': 14,\n",
        "\n",
        "    'xtick.direction': 'inout',\n",
        "    'ytick.direction': 'inout',\n",
        "\n",
        "    'grid.linestyle': '-',         # solid\n",
        "    'grid.linewidth': 1.5,        # in points\n",
        "    'grid.alpha':     1,        # transparency, between 0.0 and 1.0\n",
        "}\n",
        "# plt.style.use('fivethirtyeight')\n",
        "matplotlib.rcParams.update(params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ql2mIAKBIEND"
      },
      "outputs": [],
      "source": [
        "from numba.parfors.parfor import maximize_fusion_inner\n",
        "#LABWORK7 - REDUCE NORMAL\n",
        "\n",
        "Data_path=\"/content/drive/MyDrive/HPC/\"\n",
        "Image_path=Data_path+\"Test_org.jpg\"\n",
        "Image_path_2=Data_path+\"Test_org_2.jpg\"\n",
        "# blockDim.x,y,z gives the number of threads in a block, in the particular direction\n",
        "# gridDim.x,y,z gives the number of blocks in a grid, in the particular direction\n",
        "# blockDim.x * gridDim.x gives the number of threads in a grid\n",
        "\n",
        "\n",
        "# Grayscale\n",
        "@cuda.jit\n",
        "def grayscale(src, dst):\n",
        "  tidx = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
        "  tidy = cuda.threadIdx.y + cuda.blockIdx.y * cuda.blockDim.y\n",
        "  g = np.uint16((src[tidx,tidy, 0] + src[tidx,tidy, 1] + src[tidx,tidy, 2]) / 3)\n",
        "  dst[tidx,tidy, 0] = dst[tidx,tidy, 1] = dst[tidx,tidy, 2] = g\n",
        "\n",
        "\n",
        "@cuda.jit\n",
        "def main(src,dst,max,min):\n",
        "  tidx = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
        "  #dst[tidx,0] = np.uint16((src[tidx,0] - min)/(max-min)*255)\n",
        "  tidy = cuda.threadIdx.y + cuda.blockIdx.y * cuda.blockDim.y\n",
        "  g = np.uint16((src[tidx,tidy,0] - min)/(max-min)*255)\n",
        "  dst[tidx,tidy,0]=dst[tidx,tidy,1] = dst[tidx,tidy,2] = g\n",
        "\n",
        "\n",
        "# Image data\n",
        "img_data=plt.imread(Image_path)\n",
        "\n",
        "# Shape of the figure\n",
        "(imageHeight,imageWidth,_)=img_data.shape\n",
        "pixelCount = imageWidth * imageHeight\n",
        "out_img = np.array(img_data, copy=True)\n",
        "\n",
        "\n",
        "def compare(blockSize, option):\n",
        "  #Grid size -> chunk\n",
        "  #int to ensure it's an interger\n",
        "  # BlockSize should be the multiplication of 32\n",
        "  grid_1 = int(imageHeight/blockSize)\n",
        "  grid_2 = int(imageWidth/blockSize)\n",
        "  print(grid_1,grid_2)\n",
        "  gridSize=(grid_1,grid_2)\n",
        "  blockSize=(blockSize,blockSize)\n",
        "\n",
        "  # Start timing\n",
        "  start_time=time.time()\n",
        "\n",
        "  # Copy image to the device from host(CPU)\n",
        "  devSrc = cuda.to_device(img_data)\n",
        "\n",
        "  # Allocate memory on the device (GPU)\n",
        "  devDst_gray = cuda.device_array((imageHeight,imageWidth,3), np.uint16)\n",
        "\n",
        "  # Reduce finding max, min\n",
        "  grayscale[gridSize,blockSize](devSrc, devDst_gray)\n",
        "\n",
        "  # Copy from device to host\n",
        "  midDst = devDst_gray.copy_to_host()\n",
        "  grayDst = midDst\n",
        "  midDst_flatten=midDst.flatten().reshape((pixelCount,3))[:,2]\n",
        "  # Find max,min\n",
        "  max_in = np.amax(midDst_flatten)\n",
        "  print(max_in)\n",
        "  min_in = np.amin(midDst_flatten)\n",
        "  print(min_in)\n",
        "\n",
        "  # Convert\n",
        "  midSrc_gray = cuda.to_device(midDst)\n",
        "  devDst = cuda.device_array((imageHeight,imageWidth,3), np.uint16)\n",
        "  main[gridSize,blockSize](midSrc_gray,devDst,max_in,min_in)\n",
        "  hostDst=devDst.copy_to_host()\n",
        "\n",
        "  # Stop timing\n",
        "  end_time=time.time()\n",
        "\n",
        "  #Get the running time\n",
        "  run_time=end_time-start_time\n",
        "\n",
        "  if option == True:\n",
        "    return run_time, grayDst, hostDst\n",
        "  else: return run_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6RW7LiWg_s1"
      },
      "outputs": [],
      "source": [
        "from numba.parfors.parfor import maximize_fusion_inner\n",
        "#LABWORK7 - REDUCE NO SHARE MEMORY\n",
        "\n",
        "Data_path=\"/content/drive/MyDrive/HPC/\"\n",
        "Image_path=Data_path+\"Test_org.jpg\"\n",
        "Image_path_2=Data_path+\"Test_org_2.jpg\"\n",
        "# blockDim.x,y,z gives the number of threads in a block, in the particular direction\n",
        "# gridDim.x,y,z gives the number of blocks in a grid, in the particular direction\n",
        "# blockDim.x * gridDim.x gives the number of threads in a grid\n",
        "\n",
        "\n",
        "# Grayscale\n",
        "@cuda.jit\n",
        "def grayscale(src, dst):\n",
        "  tidx = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
        "  tidy = cuda.threadIdx.y + cuda.blockIdx.y * cuda.blockDim.y\n",
        "  g = np.uint16((src[tidx,tidy, 0] + src[tidx,tidy, 1] + src[tidx,tidy, 2]) / 3)\n",
        "  dst[tidx,tidy, 0] = dst[tidx,tidy, 1] = dst[tidx,tidy, 2] = g\n",
        "\n",
        "@cuda.jit\n",
        "def sort_min(src,dst):\n",
        "  localtid = cuda.threadIdx.x\n",
        "  tid = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
        "  i=1\n",
        "  while i < cuda.blockDim.x :\n",
        "    #index = np.uint64(i*2*localtid)\n",
        "    #if index < cuda.blockDim.x:\n",
        "    if localtid % (i * 2) == 0:\n",
        "      if src[tid] > src[tid + i]:\n",
        "        src[tid] = src[tid+i]\n",
        "      i = i * 2\n",
        "  dst[tid] = src[tid]\n",
        "\n",
        "@cuda.jit\n",
        "def sort_max(src,dst):\n",
        "  localtid = cuda.threadIdx.x\n",
        "  tid = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
        "  i=1\n",
        "  while i < cuda.blockDim.x :\n",
        "    #index = np.uint64(i*2*localtid)\n",
        "    #if index < cuda.blockDim.x:\n",
        "    if localtid % (i * 2) == 0:\n",
        "      if src[tid] > src[tid + i]:\n",
        "        src[tid] = src[tid]\n",
        "      i = i * 2\n",
        "  dst[tid] = src[tid]\n",
        "\n",
        "\n",
        "@cuda.jit\n",
        "def main(src,dst,max,min):\n",
        "  tidx = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
        "  #dst[tidx,0] = np.uint16((src[tidx,0] - min)/(max-min)*255)\n",
        "  tidy = cuda.threadIdx.y + cuda.blockIdx.y * cuda.blockDim.y\n",
        "  g = np.uint16((src[tidx,tidy,0] - min)/(max-min)*255)\n",
        "  dst[tidx,tidy,0]=dst[tidx,tidy,1] = dst[tidx,tidy,2] = g\n",
        "\n",
        "\n",
        "# Image data\n",
        "img_data=plt.imread(Image_path)\n",
        "\n",
        "# Shape of the figure\n",
        "(imageHeight,imageWidth,_)=img_data.shape\n",
        "pixelCount = imageWidth * imageHeight\n",
        "out_img = np.array(img_data, copy=True)\n",
        "\n",
        "\n",
        "def compare(blockSize_unit, option):\n",
        "  #Grid size -> chunk\n",
        "  #int to ensure it's an interger\n",
        "  # BlockSize should be the multiplication of 32\n",
        "  grid_1 = int(imageHeight/blockSize_unit)\n",
        "  grid_2 = int(imageWidth/blockSize_unit)\n",
        "  print(grid_1,grid_2)\n",
        "  gridSize=(grid_1,grid_2)\n",
        "  blockSize=(blockSize_unit,blockSize_unit)\n",
        "\n",
        "  # Start timing\n",
        "  start_time=time.time()\n",
        "\n",
        "  # Copy image to the device from host(CPU)\n",
        "  devSrc = cuda.to_device(img_data)\n",
        "\n",
        "  # Allocate memory on the device (GPU)\n",
        "  devDst_gray = cuda.device_array((imageHeight,imageWidth,3), np.uint16)\n",
        "\n",
        "  # Reduce finding max, min\n",
        "  grayscale[gridSize,blockSize](devSrc, devDst_gray)\n",
        "  # Copy from device to host\n",
        "  midDst_gray = devDst_gray.copy_to_host()\n",
        "  grayDst = midDst_gray\n",
        "\n",
        "  # Sort min,max\n",
        "  # Flatten and get the array\n",
        "  midDst_flatten=midDst_gray[:,:,0].flatten()\n",
        "  #midDst_flatten = np.ascontiguousarray(midDst_flatten)\n",
        "  (length,)=midDst_flatten.shape\n",
        "  gridSize_small= int(length/blockSize_unit)\n",
        "  print(midDst_flatten)\n",
        "\n",
        "  # Sort\n",
        "  #stream = cuda.stream()\n",
        "\n",
        "  midSrc = cuda.to_device(midDst_flatten)\n",
        "  midDst = cuda.device_array(np.array(midDst_flatten,copy=True))\n",
        "  sort_max[gridSize_small,blockSize_unit](midSrc,midDst)\n",
        "  midDst_max=midDst.copy_to_host()\n",
        "  max_in=int(midDst_max[0])\n",
        "\n",
        "  midSrc = cuda.to_device(midDst_flatten)\n",
        "  midDst = cuda.device_array(np.array(midDst_flatten,copy=True),np.unint16)\n",
        "  sort_min[gridSize_small,blockSize_unit](midSrc)\n",
        "  midDst_min=midDst.copy_to_host()\n",
        "  min_in=int(midDst_min[0])\n",
        "\n",
        "  print(max_in)\n",
        "\n",
        "  # Convert\n",
        "  midSrc_sort = cuda.to_device(midDst)\n",
        "  devDst = cuda.device_array((imageHeight,imageWidth,3), np.uint16)\n",
        "  main[gridSize,blockSize](midSrc_sort,devDst,max_in,min_in)\n",
        "  hostDst=devDst.copy_to_host()\n",
        "\n",
        "  # Stop timing\n",
        "  end_time=time.time()\n",
        "\n",
        "  #Get the running time\n",
        "  run_time=end_time-start_time\n",
        "\n",
        "  if option == True:\n",
        "    return run_time, grayDst, hostDst\n",
        "  else: return run_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avWULBqZUXlw",
        "outputId": "3d16bfff-72d1-46ed-a102-ea9b3adffbca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "37 60\n",
            "[17 15 15 ...  0  0  0]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/misc/dummyarray.py:166: RuntimeWarning: overflow encountered in long_scalars\n",
            "  self.size = functools.reduce(operator.mul, self.shape, 1)\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:97: RuntimeWarning: overflow encountered in long_scalars\n",
            "  self.size = int(functools.reduce(operator.mul, self.shape, 1))\n"
          ]
        }
      ],
      "source": [
        "#Output run_time and hostDst\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.title(\"Original image\")\n",
        "plt.imshow(img_data)\n",
        "\n",
        "blockSize = 32\n",
        "run_time, midDst, hostDst= compare(blockSize,option=True)\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "# Show the normal image\n",
        "plt.title(\"Normal gray image\")\n",
        "plt.imshow(midDst)\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "# Show the resule image\n",
        "plt.title(\"Result image\")\n",
        "plt.imshow(hostDst)\n",
        "\n",
        "# Save the image\n",
        "plt.savefig(Data_path+\"Test_result_LW7.jpg\")\n",
        "print(\"The run time is\",run_time,\"s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62PDosOrY9H_",
        "outputId": "478b8800-0cd4-4dbe-b43d-131ac5eb45cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1200, 1920)\n"
          ]
        }
      ],
      "source": [
        "(imageHeight,imageWidth,_)=img_data.shape\n",
        "pixelCount = imageWidth * imageHeight\n",
        "\n",
        "midDst_flatten=img_data[:,:,0]\n",
        "print(midDst_flatten.shape)\n",
        "#res_image = np.reshape(midDst_flatten,(imageHeight, imageWidth))\n",
        "#print(res_image)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
